import re
import unicodedata
from pathlib import Path
from typing import Any, Dict, List, Optional

import xml.etree.ElementTree as ET
import streamlit as st
from pypdf import PdfReader


class DocumentLoader:
    """åŒ»è–¬å“æ–‡æ›¸ã‚’èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹"""

    def __init__(self, data_dir: str = "data") -> None:
        """
        Args:
            data_dir: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        """
        self.data_dir = Path(data_dir)

    def _detect_document_type(self, file_name: str) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š

        Args:
            file_name: ãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            æ–‡æ›¸ã‚¿ã‚¤ãƒ—
        """
        # å…¨è§’ã‚’åŠè§’ã«å¤‰æ›
        file_name_normalized = unicodedata.normalize('NFKC', file_name)

        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå„ªå…ˆé †ä½é †ï¼‰- æ­£è¦åŒ–å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã§åˆ¤å®š
        if file_name_normalized.endswith('.xml'):
            return 'é›»å­æ·»æ–‡'
        elif '_IF.pdf' in file_name_normalized or 'IF.pdf' in file_name_normalized:
            return 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ '
        elif '_RMP' in file_name_normalized or 'RMP' in file_name_normalized:
            return 'åŒ»è–¬å“ãƒªã‚¹ã‚¯ç®¡ç†è¨ˆç”»'
        elif 'æ‚£è€…å‘ã‘ã‚¬ã‚¤ãƒ‰' in file_name_normalized or 'æ‚£è€…å‘ã‘ã‚¬ã‚¤ãƒ‰' in file_name:
            return 'æ‚£è€…å‘ã‘åŒ»è–¬å“ã‚¬ã‚¤ãƒ‰'
        else:
            return 'ãã®ä»–'
    
    def _clean_text(self, text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
        
        Args:
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        # æ”¹è¡Œã®æ•´ç†
        text = re.sub(r'\n{3,}', '\n\n', text)  # 3ã¤ä»¥ä¸Šã®é€£ç¶šæ”¹è¡Œã‚’2ã¤ã«
        
        # å…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€
        text = text.replace('ã€€', ' ')  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’åŠè§’ã«
        
        # ä¸è¦ãªç©ºç™½ã®é™¤åŽ»
        text = re.sub(r' {2,}', ' ', text)  # é€£ç¶šã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
        
        return text.strip()
    
    def _extract_sections_from_text(self, text: str, file_name: str) -> List[Dict[str, Any]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦‹å‡ºã—å˜ä½ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
        
        Args:
            text: å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ
            file_name: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆ
        """
        sections = []
        
        # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šã§åˆ†å‰²
        pages = text.split('--- ãƒšãƒ¼ã‚¸')
        
        for page_text in pages:
            if not page_text.strip():
                continue
            
            # ãƒšãƒ¼ã‚¸ç•ªå·ã®æŠ½å‡º
            page_match = re.match(r'(\d+) ---', page_text)
            page_num = int(page_match.group(1)) if page_match else None
            
            section_text = page_text
            if page_match:
                section_text = page_text[page_match.end():]
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦ä¿å­˜
            sections.append({
                'text': self._clean_text(section_text),
                'page': page_num,
                'heading': self._extract_first_heading(section_text),
                'file_name': file_name
            })
        
        return sections
    
    def _extract_first_heading(self, text: str) -> Optional[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€åˆã®è¦‹å‡ºã—ã‚’æŠ½å‡º"""
        lines = text.split('\n')[:5]  # æœ€åˆã®5è¡Œã‚’ç¢ºèª
        
        for line in lines:
            line = line.strip()
            # æ•°å­—ã‚„è¨˜å·ã§å§‹ã¾ã‚‹è¦‹å‡ºã—ã‚‰ã—ã„è¡Œ
            if re.match(r'^[\d\ã€].{3,50}', line):
                return line
        
        return None

    def load_pdf(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """
        PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™

        Args:
            file_path: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            dict: æ–‡æ›¸æƒ…å ±
        """
        try:
            reader = PdfReader(file_path)

            full_text_parts: List[str] = []
            for page_num, page in enumerate(reader.pages, 1):
                page_text = page.extract_text() or ""
                full_text_parts.append(f"\n--- ãƒšãƒ¼ã‚¸ {page_num} ---\n{page_text}")
            full_text = "".join(full_text_parts)
            
            # æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
            doc_type = self._detect_document_type(file_path.name)
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
            sections = self._extract_sections_from_text(full_text, file_path.name)
            
            return {
                'full_text': full_text,
                'sections': sections,
                'file_name': file_path.name,
                'file_path': str(file_path),
                'pages': len(reader.pages),
                'doc_type': doc_type,
                'doc_type_ja': doc_type
            }
            
        except Exception as e:
            print(f"âŒ PDFã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {file_path.name}")
            print(f"   ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def load_xml(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """
        XMLãƒ•ã‚¡ã‚¤ãƒ«(é›»å­æ·»æ–‡)ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: XMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            dict: æ–‡æ›¸æƒ…å ±
        """
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # XMLã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            text = ET.tostring(root, encoding='unicode', method='text')
            
            sections = [{
                'text': self._clean_text(text),
                'page': None,
                'heading': 'é›»å­æ·»æ–‡',
                'file_name': file_path.name
            }]
            
            return {
                'full_text': text,
                'sections': sections,
                'file_name': file_path.name,
                'file_path': str(file_path),
                'pages': None,
                'doc_type': 'é›»å­æ·»æ–‡',
                'doc_type_ja': 'é›»å­æ·»æ–‡'
            }
            
        except Exception as e:
            print(f"âŒ XMLã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {file_path.name}")
            print(f"   ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def load_product_documents(self, product_type: str, company_type: str) -> List[Dict[str, Any]]:
        """
        æŒ‡å®šã•ã‚ŒãŸè£½å“ã‚¿ã‚¤ãƒ—ã¨ä¼šç¤¾ã‚¿ã‚¤ãƒ—ã®æ–‡æ›¸ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            product_type: "è¡€æ¼¿åˆ†ç”»è£½å‰¤", "IBDè£½å‰¤", "æŠ—ã†ã¤è£½å‰¤" ãªã©
            company_type: "è‡ªç¤¾" or "ä»–ç¤¾"
            
        Returns:
            List[Dict]: èª­ã¿è¾¼ã‚“ã æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
        """
        documents = []
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        folder_path = self.data_dir / product_type / company_type
        
        if not folder_path.exists():
            print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {folder_path}")
            return documents
        
        # PDFã¨XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æŽ¢ç´¢
        pdf_files = list(folder_path.rglob("*.pdf"))
        xml_files = list(folder_path.rglob("*.xml"))
        
        all_files = pdf_files + xml_files
        
        print(f"  ðŸ“‚ {len(all_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ (PDF: {len(pdf_files)}, XML: {len(xml_files)})")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        for file_path in all_files:
            if file_path.suffix == '.pdf':
                doc = self.load_pdf(file_path)
            elif file_path.suffix == '.xml':
                doc = self.load_xml(file_path)
            else:
                continue
            
            if doc:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                doc['product_type'] = product_type
                doc['company_type'] = company_type
                
                # è£½å“åã‚’æŽ¨å®šï¼ˆãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰ï¼‰
                product_name = file_path.parent.name
                doc['product_name'] = product_name
                
                documents.append(doc)
        
        return documents
    
    def load_all_documents(self) -> List[Dict[str, Any]]:
        """
        å…¨è£½å“ã‚¿ã‚¤ãƒ—ã€å…¨ä¼šç¤¾ã‚¿ã‚¤ãƒ—ã®æ–‡æ›¸ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            List[Dict]: èª­ã¿è¾¼ã‚“ã å…¨æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
        """
        all_documents = []
        
        # è£½å“ã‚¿ã‚¤ãƒ—ã®å®šç¾©
        product_types = ["è¡€æ¼¿åˆ†ç”»è£½å‰¤", "IBDè£½å‰¤", "æŠ—ã†ã¤è£½å‰¤"]
        company_types = ["è‡ªç¤¾", "ä»–ç¤¾"]
        
        print("\n=== å…¨è£½å“ã®æ–‡æ›¸ã‚’èª­ã¿è¾¼ã¿ ===")
        
        for product_type in product_types:
            product_path = self.data_dir / product_type
            if not product_path.exists():
                print(f"âš ï¸ {product_type}ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                continue
            
            print(f"\nã€{product_type}ã€‘")
            
            for company_type in company_types:
                print(f"  {company_type}:")
                docs = self.load_product_documents(product_type, company_type)
                all_documents.extend(docs)
                print(f"    â†’ {len(docs)}æ–‡æ›¸èª­ã¿è¾¼ã¿å®Œäº†")
        
        return all_documents
    
    def get_available_products(self) -> Dict[str, Dict[str, List[str]]]:
        """
        åˆ©ç”¨å¯èƒ½ãªå…¨è£½å“ãƒªã‚¹ãƒˆã‚’å–å¾—
        
        Returns:
            Dict: {
                'è¡€æ¼¿åˆ†ç”»è£½å‰¤': {'è‡ªç¤¾': [...], 'ä»–ç¤¾': [...]},
                'IBDè£½å‰¤': {'è‡ªç¤¾': [...], 'ä»–ç¤¾': [...]},
                'æŠ—ã†ã¤è£½å‰¤': {'è‡ªç¤¾': [...], 'ä»–ç¤¾': [...]}
            }
        """
        products: Dict[str, Dict[str, List[str]]] = {}
        
        # è£½å“ã‚¿ã‚¤ãƒ—ã®å®šç¾©
        product_types = ["è¡€æ¼¿åˆ†ç”»è£½å‰¤", "IBDè£½å‰¤", "æŠ—ã†ã¤è£½å‰¤"]
        
        for product_type in product_types:
            product_path = self.data_dir / product_type
            if not product_path.exists():
                continue
            
            products[product_type] = {'è‡ªç¤¾': [], 'ä»–ç¤¾': []}
            
            for company_type in ('è‡ªç¤¾', 'ä»–ç¤¾'):
                company_path = product_path / company_type
                if company_path.exists():
                    products[product_type][company_type] = sorted(
                        d.name for d in company_path.iterdir() if d.is_dir()
                    )
        
        return products
    
    def get_document_stats(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        èª­ã¿è¾¼ã‚“ã æ–‡æ›¸ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚

        Args:
            documents: æ–‡æ›¸è¾žæ›¸ã®ãƒªã‚¹ãƒˆ

        Returns:
            total_docs, by_type, by_product, by_product_type, by_company ã‚’å«ã‚€è¾žæ›¸
        """
        stats = {
            'total_docs': len(documents),
            'by_type': {},
            'by_product': {},
            'by_product_type': {},
            'by_company': {}
        }
        
        for doc in documents:
            # æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¥
            doc_type = doc.get('doc_type_ja', 'ä¸æ˜Ž')
            stats['by_type'][doc_type] = stats['by_type'].get(doc_type, 0) + 1
            
            # è£½å“åˆ¥
            product = doc.get('product_name', 'ä¸æ˜Ž')
            stats['by_product'][product] = stats['by_product'].get(product, 0) + 1
            
            # è£½å“ã‚¿ã‚¤ãƒ—åˆ¥
            product_type = doc.get('product_type', 'ä¸æ˜Ž')
            stats['by_product_type'][product_type] = stats['by_product_type'].get(product_type, 0) + 1
            
            # ä¼šç¤¾ã‚¿ã‚¤ãƒ—åˆ¥
            company_type = doc.get('company_type', 'ä¸æ˜Ž')
            stats['by_company'][company_type] = stats['by_company'].get(company_type, 0) + 1
        
        return stats

    def load_drug_prices(self) -> Dict[str, Any]:
        """
        è–¬ä¾¡æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ã€‚

        Returns:
            {'æ³¨å°„å‰¤': DataFrame, 'å†…æœè–¬': DataFrame, ...} ã®è¾žæ›¸
        """
        import pandas as pd

        prices: Dict[str, Any] = {}
        price_dir = self.data_dir / "è–¬ä¾¡"

        if not price_dir.exists():
            print(f"âš ï¸ è–¬ä¾¡ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {price_dir}")
            return prices

        excel_files = list(price_dir.glob("*.xlsx"))
        print(f"\n=== è–¬ä¾¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ ===")
        print(f"ç™ºè¦‹ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(excel_files)}")

        for excel_file in excel_files:
            try:
                print(f"  èª­ã¿è¾¼ã¿ä¸­: {excel_file.name}")
                df = pd.read_excel(excel_file)

                if 'æ³¨å°„å‰¤' in excel_file.name:
                    prices['æ³¨å°„å‰¤'] = df
                elif 'å†…æœè–¬' in excel_file.name or 'å†…æœ' in excel_file.name:
                    prices['å†…æœè–¬'] = df
                else:
                    prices[excel_file.stem] = df

                print(f"    â†’ {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")

            except Exception as e:
                print(f"âŒ è–¬ä¾¡ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {excel_file.name}")
                print(f"   ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return prices


def test_loader() -> None:
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å‹•ä½œç¢ºèªç”¨ã€‚"""
    loader = DocumentLoader()
    
    print("=" * 70)
    print("=== åˆ©ç”¨å¯èƒ½ãªè£½å“ä¸€è¦§ ===")
    products = loader.get_available_products()
    for product_type, companies in products.items():
        print(f"\nã€{product_type}ã€‘")
        for company_type, product_list in companies.items():
            print(f"  {company_type}: {len(product_list)}è£½å“")
    
    # å…¨æ–‡æ›¸ã‚’èª­ã¿è¾¼ã¿
    all_docs = loader.load_all_documents()
    
    print("\n" + "=" * 70)
    print(f"=== èª­ã¿è¾¼ã¿å®Œäº† ===")
    print(f"ç·æ–‡æ›¸æ•°: {len(all_docs)}")
    
    if all_docs:
        stats = loader.get_document_stats(all_docs)
        
        print(f"\nã€è£½å“ã‚¿ã‚¤ãƒ—åˆ¥ã€‘")
        for product_type, count in stats['by_product_type'].items():
            print(f"  {product_type}: {count}æ–‡æ›¸")
        
        print(f"\nã€ä¼šç¤¾ã‚¿ã‚¤ãƒ—åˆ¥ã€‘")
        for company_type, count in stats['by_company'].items():
            print(f"  {company_type}: {count}æ–‡æ›¸")
        
        print(f"\nã€æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¥ã€‘")
        for doc_type, count in stats['by_type'].items():
            print(f"  {doc_type}: {count}æ–‡æ›¸")
        
        # IFãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±è¨ˆ
        if_docs = [d for d in all_docs if d['doc_type'] == 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ ']
        print(f"\nã€ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ ã€‘")
        print(f"  ç·æ•°: {len(if_docs)}æ–‡æ›¸")
        if_by_product = {}
        for doc in if_docs:
            pt = doc['product_type']
            if_by_product[pt] = if_by_product.get(pt, 0) + 1
        for pt, count in if_by_product.items():
            print(f"  {pt}: {count}æ–‡æ›¸")
    
    # è–¬ä¾¡æƒ…å ±ã®èª­ã¿è¾¼ã¿
    print("\n" + "=" * 70)
    prices = loader.load_drug_prices()
    
    if prices:
        print(f"\nã€è–¬ä¾¡ãƒ‡ãƒ¼ã‚¿ã€‘")
        for category, df in prices.items():
            print(f"  {category}: {len(df)}è¡Œ")
            if len(df) > 0:
                print(f"    åˆ—: {list(df.columns[:5])}...")


if __name__ == "__main__":
    test_loader()